{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ce78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals,print_function\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re#正则表达式模块，帮助你检查一个字符串是否与某种模式匹配\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc31808",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0#标记文本序列开始\n",
    "EOS_token = 1#标记文本序列结束\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}#把单词映射为索引的词典\n",
    "        self.word2count = {}#统计出现过的单词出现次数\n",
    "        self.index2word = {0:'SOS',1:'EOS'}#把索引映射为单词的词典\n",
    "        self.n_words = 2#词典中单词数量\n",
    "    def addSentence(self,sentence):\n",
    "        #把句子按空格分割，把句子每个单词都加入词典\n",
    "        for word in sentence.split(' '):#以空格为基准分割句子\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self,word):\n",
    "        #如果单词之前没有出现过，加入词典\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        #单词之前出现\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b09aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将unicode码转换为普通的ASCII码\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "    c for c in unicodedata.normalize('NFD',s)\n",
    "    if unicodedata.category(c)!='Mn')\n",
    "#def sub(pattern, repl, string, count=0, flags=0):\n",
    "#\t    \"\"\"Return the string obtained by replacing the leftmost\n",
    "#\t    non-overlapping occurrences of the pattern in string by the\n",
    "#\t    replacement repl.  repl can be either a string or a callable;\n",
    "#\t    if a string, backslash escapes in it are processed.  If it is\n",
    "#\t    a callable, it's passed the match object and must return\n",
    "#\t    a replacement string to be used.\"\"\"\n",
    "#\t    return _compile(pattern, flags).sub(repl, string, count)\n",
    "\n",
    "#将句子中所有字母转换为小写，一处一些不是字母的字符\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())#转换为小写\n",
    "    s = re.sub(r\"([.!?])\",r\"\\1\",s)# 在.!?前加一个空格\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\",r\" \",s)#匹配多个连续的非字母，并将多个连续的非字母替换为一个' '\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b065bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse = False):#加入bool reverse是因为方便双向翻译,即交换输入序列与输出序列 \n",
    "    print(\"Reading lines...\")\n",
    "    #读入文件，按回车分行，每一行都存储在Lines中\n",
    "    lines = open('data/%s-%s.txt'%(lang1,lang2),encoding = 'utf-8').read().strip().split('\\n')#因为文件名长这样：eng-fra.txt\n",
    "    \n",
    "    #每一行 用tab分割，前面是英文。后面是法文\n",
    "    pairs = [[normalizeString(s) for s in line.split('\\t')] for line in lines]\n",
    "    \n",
    "    #reverse = True法译英\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang,output_lang,pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd825c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10 #句子最大长度是10\n",
    "# 过滤出一些长度不超过10，以一下前缀开头的句子做训练集\n",
    "eng_prefixes = (\n",
    "'i am','i m',\n",
    "'he is','he s',\n",
    "'she is','she s',\n",
    "'you are','you re',\n",
    "'we are','we re',\n",
    "'they are','they re')\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and\\\n",
    "      len(p[1].split(' ')) < MAX_LENGTH and\\\n",
    "      p[1].startswith(eng_prefixes)#startswith()判断是否以此字符串从指定索引开始的子字符串是否以指定前缀开始\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7fd23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read %s sentence pairs %len(pairs)\n",
      "Trimmed to 12900 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 6501\n",
      "eng 4389\n",
      "['elle est rapide pour tout.', 'she is quick at everything.']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse= False):\n",
    "    input_lang, output_lang,pairs = readLangs(lang1,lang2,reverse)\n",
    "    print(\"Read %s sentence pairs %len(pairs)\")\n",
    "    pairs = filterPairs(pairs)\n",
    "    print('Trimmed to %s sentence pairs'%len(pairs))\n",
    "    print('Counting words...')\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])#input_lang为句子pair[0]创建词典\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print('Counted words:')\n",
    "    print(input_lang.name,input_lang.n_words)\n",
    "    print(output_lang.name,output_lang.n_words)\n",
    "    return input_lang,output_lang,pairs\n",
    "        \n",
    "input_lang,output_lang,pairs=prepareData('eng','fra',True)#法译英\n",
    "print(random.choice(pairs))#返回一个列表，元组或字符串的随机项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4519d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je suis en bas.', 'i m downstairs.']\n",
      "input: tensor([[   5,   10,   13, 1086,    1]], device='cuda:0')\n",
      "target: tensor([[  2,   3, 603,   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#创建句子的tensor\n",
    "def indexesFromSentence(lang,sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]#返回lang.word2index[word] 索引\n",
    "\n",
    "#在句子的tensor中，加入EOS符号\n",
    "def tensorFromSentence(lang,sentence):\n",
    "    # 对句子进行分割并遍历每一个词汇, 然后使用lang的word2index方法找到它对应的索引\n",
    "    # 这样就得到了该句子对应的数值列表\n",
    "    indexes = indexesFromSentence(lang,sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    # 将其使用torch.tensor封装成张量, 并改变它的形状为nx1, 以方便后续计算\n",
    "    return torch.tensor(indexes,dtype = torch.long,device = device).view(1,-1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    #将语言对转换为张量对，参数pair为一个语言对\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])# 输入序列的张量\n",
    "    target_tensor = tensorFromSentence(output_lang,pair[1])#输出序列的张量\n",
    "    return (input_tensor,target_tensor)\n",
    "\n",
    "sample_pairs = random.choice(pairs)\n",
    "print(sample_pairs)\n",
    "input_tensor,target_tensor = tensorsFromPair(sample_pairs)\n",
    "print('input:',input_tensor)\n",
    "print('target:',target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b202ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.gru(embedded,hidden)\n",
    "        return output,hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86586a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#含注意力机制的解码器 （分解向量C）\n",
    "\n",
    "       #初始化函数中的参数有4个, hidden_size代表解码器中GRU的输入尺寸，也是它的隐层节点数\n",
    "       #output_size代表整个解码器的输出尺寸, 也是我们希望得到的指定尺寸即目标语言的词表大小\n",
    "       # dropout_p代表我们使用dropout层时的置零比率，默认0.1, max_length代表句子的最大长度\"\"\"\n",
    "\n",
    "        # 根据attention的QKV理论，attention的输入参数为三个Q，K，V，\n",
    "        # 第一步，使用Q与K进行attention权值计算得到权重矩阵, 再与V做矩阵乘法, 得到V的注意力表示结果.\n",
    "        # 这里常见的计算方式有三种:\n",
    "        # 1，将Q，K进行纵轴拼接, 做一次线性变化, 再使用softmax处理获得结果最后与V做张量乘法\n",
    "        # 2，将Q，K进行纵轴拼接, 做一次线性变化后再使用tanh函数激活, 然后再进行内部求和, 最后使用softmax处理获得结果再与V做张量乘法\n",
    "        # 3，将Q与K的转置做点积运算, 然后除以一个缩放系数, 再使用softmax处理获得结果最后与V做张量乘法\n",
    " \n",
    "        # 说明：当注意力权重矩阵和V都是三维张量且第一维代表为batch条数时, 则做bmm运算.\n",
    " \n",
    "        # 第二步, 根据第一步采用的计算方法, 如果是拼接方法，则需要将Q与第二步的计算结果再进行拼接, \n",
    "        # 如果是转置点积, 一般是自注意力, Q与V相同, 则不需要进行与Q的拼接.因此第二步的计算方式与第一步采用的全值计算方法有关.\n",
    "        # 第三步，最后为了使整个attention结构按照指定尺寸输出, 使用线性层作用在第二步的结果上做一个线性变换. 得到最终对Q的注意力表示.\n",
    " \n",
    "        # 我们这里使用的是第一步中的第一种计算方式, 因此需要一个线性变换的矩阵, 实例化nn.Linear\n",
    "        # 因为它的输入是Q，K的拼接, 所以输入的第一个参数是self.hidden_size * 2，第二个参数是self.max_length\n",
    "        # 这里的Q是解码器的Embedding层的输出, K是解码器GRU的隐层输出，因为首次隐层还没有任何输出，会使用编码器的隐层输出\n",
    "        # 而这里的V是编码器层的输出\n",
    "\n",
    "         # 接着我们实例化另外一个线性层, 它是attention理论中的第四步的线性层，用于规范输出尺寸\n",
    "        # 这里它的输入来自第三步的结果, 因为第三步的结果是将Q与第二步的结果进行拼接, 因此输入维度是self.hidden_size * 2\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, \n",
    "                dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size # 目标语言的单词数量\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2,self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2,self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input是编码器的上一步输出 或者 真实的前一个单词\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 计算注意力权重\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0],hidden[0]),1)),dim=1)\n",
    "        \n",
    "        # torch.bmm(a,b):计算两个tensor的Hadamard乘积，\n",
    "        # tensor a 的大小为(b,h1,w),\n",
    "        # tensor b 的大小为(b,w,h2)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), # 1, 1， max_length\n",
    "                    encoder_outputs.unsqueeze(0)) # 1, max_length， hidden_size\n",
    "        \n",
    "        # 输出的attn_applied 大小为 (1, 1, hidden_size)\n",
    "        # embedded: (1, 1, hidden_size)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]),1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output,hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]),dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089066cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练，用Teacing forcing稍微帮助他一下\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "      encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)  # 源语言句子长度\n",
    "    target_length = target_tensor.size(0) # 目标语言句子长度\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length,encoder.hidden_size,device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei],encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0,0]  # 保存encoder每一步的隐藏层状态\n",
    "  \n",
    "    decoder_input = torch.tensor([[SOS_token]],device=device) # decoder的第一个输入是SOS\n",
    "\n",
    "    decoder_hidden = encoder_hidden # encoder最后一步隐藏层状态\n",
    "\n",
    "    use_teacher_forcing = True if random.random()<teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "    # 强制输入target的input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "              decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "\n",
    "    else:\n",
    "    # 输入预测的input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "              decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv,topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "            if decoder_input.item() == EOS_token: break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/target_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a5581ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm%ds'%(m,s)\n",
    "def timeSince(since,percent):\n",
    "    now = time.time()\n",
    "    s = now -since\n",
    "    es = s/(percent)\n",
    "    rs = es -s\n",
    "    return '%s(-%S)'%(asMinutes(s),asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190de452",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 256, got 1280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-15bb889b18f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattn_decoder1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m75000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-15bb889b18f7>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         loss = train(input_tensor, target_tensor,encoder,\n\u001b[1;32m---> 34\u001b[1;33m                      decoder, encoder_optimizer, decoder_optimizer,criterion)\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-69a1da6b52f5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[1;32m---> 20\u001b[1;33m             input_tensor[ei],encoder_hidden)\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mei\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 保存encoder每一步的隐藏层状态\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Augustine\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d82467b8352d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Augustine\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Augustine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    845\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Augustine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Augustine\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    205\u001b[0m             raise RuntimeError(\n\u001b[0;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 207\u001b[1;33m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 256, got 1280"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000,\n",
    "               plot_every=100,learning_rate = 0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0 \n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(),lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(),lr=learning_rate)\n",
    "\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1,n_iters+1):\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor,encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer,criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every ==0:\n",
    "            print_loss_avg = print_loss_total/print_every\n",
    "            print_loss_total = 0 \n",
    "            print(\"%s (%d %d%%) %.4f\"%(timeSince(start,iter/n_iters),\n",
    "             iter, iter / n_iters*100, print_loss_avg))\n",
    "      \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total =0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1,attn_decoder1,75000,print_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea93c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length =MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang,sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length,encoder.hidden_size,device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0,0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]],device=device)\n",
    "\n",
    "        decoder_hidden=encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden,decoder_attention = decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di+1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Augustine] *",
   "language": "python",
   "name": "conda-env-Augustine-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
