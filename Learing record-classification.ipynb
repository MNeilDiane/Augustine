{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad31abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf15c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08a8001f7be4cbc93b6b3c5cfced686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torchvision数据集的输出是范围[0, 1]的PILImage图像。我们将它们转换为归一化范围[-1, 1]的tensor\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "batch_size = 4\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                               shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                               shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "           'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b59d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#functions to show image\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5#unnormalize 加载图像时，把其标准化为范围在[-1, 1]之间的张量，用([-1, 1] / 2) + 0.5 就把范围归一化到[0, 1]了。\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    #因为在plt.imshow在现实的时候输入的是（imagesize,imagesize,channels）imshow中，参数img的格式为（channels,imagesize,imagesize）,\n",
    "    #这两者的格式不一致，我们需要调用一次np.transpose函数，即np.transpose(npimg,(1,2,0))，\n",
    "    #将npimg的数据格式由（channels,imagesize,imagesize）转化为（imagesize,imagesize,channels）,进行格式的转换后方可进行显示。\n",
    "    plt.show()\n",
    "#get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#show images\n",
    "imshow(torchvision.utils.make_grid(images))#Make a grid of images.,组成图像的网络，其实就是将多张图片组合成一张图片。\n",
    "#print labels\n",
    "print(' '.join('%5s' %classes[label[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Define Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)#flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Define loss function\n",
    "criterion = nn.CrossEntroyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81250bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in emumerate(trainloader,0):\n",
    "        #get thr inputs;data is a list of [inputs,labels]\n",
    "        inputs,labels = data\n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward+backward+optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print ststistics\n",
    "        running_loss += loss.item()\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d, %5d]loss:%.3f'%(epoch + 1, i + 1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "\n",
    "print(\"Finished Training\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(),PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95606e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth:',' '.join('%5s'%classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrext = 0\n",
    "total = 0\n",
    "#since we're not training,we dont need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data\n",
    "        #calculate outputs by running image through the network\n",
    "        outputs = net(image)\n",
    "        #the class with the highest energy is what we choose as prediction\n",
    "        _. predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on tje 10000 test image: %d%%'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce628aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count predictions for each class\n",
    "correct_pred = {classname:0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "#again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(image)\n",
    "        _,predictions = torch.max(outputs,1)#其中这个 1代表行，0的话代表列。不加_,返回的是一行中最大的数。\n",
    "        #加_,则返回一行中最大数的位置\n",
    "        #collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels,prediction):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "#print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count)/total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f}% \".format(classname,accuracy)\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b9ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Augustine] *",
   "language": "python",
   "name": "conda-env-Augustine-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
